{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load .env from parent directory if needed\n",
    "env_path = Path(__file__).resolve().parent.parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Access variables\n",
    "OPENAI_API_KEY        = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_INDEX_NAME   = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_HOST         = os.getenv(\"PINECONE_HOST\")\n",
    "PINECONE_API_KEY      = os.getenv(\"PINECONE_API_KEY\")\n",
    "GEMINI_API_KEY        = os.getenv(\"GEMINI_API_KEY\")\n",
    "K_RETRIEVE            = int(os.getenv(\"K_RETRIEVE\", 5))  # default to 5\n",
    "OPENAI_API_KEY        = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisijjas/Desktop/no itba/juegos/juegos-venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö  Loaded 199 art√≠culos\n",
      "üîß  Generating embeddings ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§  Uploading to Pinecone ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚¨ÜÔ∏è  Upserting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "JSON_PATH = \"incisos-chunks.json\"\n",
    "\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "import pinecone\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê INIT MODELS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "model = SentenceTransformer(\"dariolopez/bge-m3-es-legal-tmp-6\")  # 1024-D\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê LOAD CORPUS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def load_texts_from_json(json_path: str) -> List[str]:\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return [entry[\"text\"].strip() for entry in data if \"text\" in entry]\n",
    "\n",
    "ARTICULOS = load_texts_from_json(JSON_PATH)\n",
    "print(f\"üìö  Loaded {len(ARTICULOS):,} art√≠culos\")\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê EMBEDDING FUNCTION (E5) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def embed_texts(texts: List[str]) -> List[List[float]]:\n",
    "    formatted = [f\"passage: {text}\" for text in texts]\n",
    "    return model.encode(formatted, show_progress_bar=True)\n",
    "\n",
    "print(\"üîß  Generating embeddings ‚Ä¶\")\n",
    "EMBEDS = embed_texts(ARTICULOS)\n",
    "assert len(EMBEDS[0]) == 1024, \"‚ùå Embedding dim mismatch!\"\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê PINECONE SETUP ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(name=PINECONE_INDEX_NAME, host=PINECONE_HOST)\n",
    "\n",
    "def upsert_vectors(texts: List[str],\n",
    "                   vecs: List[List[float]],\n",
    "                   batch: int = 100):\n",
    "    for i in tqdm(range(0, len(texts), batch), desc=\"‚¨ÜÔ∏è  Upserting\"):\n",
    "        batch_vecs = [\n",
    "            {\n",
    "                \"id\": f\"id-{j}\",\n",
    "                \"values\": vecs[j],\n",
    "                \"metadata\": {\"text\": texts[j]}\n",
    "            }\n",
    "            for j in range(i, min(i + batch, len(texts)))\n",
    "        ]\n",
    "        index.upsert(vectors=batch_vecs)\n",
    "\n",
    "print(\"üì§  Uploading to Pinecone ‚Ä¶\")\n",
    "upsert_vectors(ARTICULOS, EMBEDS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37bafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê RETRIEVE FUNCTION  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def retrieve(query: str, k: int = K_RETRIEVE) -> List[str]:\n",
    "    query_vec = model.encode(f\"query: {query}\")\n",
    "    res = index.query(vector=query_vec.tolist(), top_k=k, include_metadata=True)\n",
    "    return [m.metadata[\"text\"] for m in res.matches]\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê GEMINI PRO RAG ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "gemini = genai.GenerativeModel(model_name=\"gemini-2.0-flash\") \n",
    "\n",
    "def rag_answer(question: str) -> str:\n",
    "    context = \"\\n\\n\".join(retrieve(question))\n",
    "    prompt  = f\"Contexto:\\n{context}\\n\\nPregunta: {question}\\nRespuesta:\"\n",
    "    return gemini.generate_content(prompt).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Pregunta: ¬øCu√°les son las atribuciones del presidente de la Argentina?\n",
      "\n",
      "üß† Respuesta (Gemini):\n",
      " Bas√°ndonos en el texto proporcionado, las atribuciones del Presidente de la Naci√≥n Argentina son:\n",
      "\n",
      "*   **Jefe Supremo de la Naci√≥n, Jefe del Gobierno y responsable pol√≠tico de la administraci√≥n general del pa√≠s.**\n",
      "*   **Ejercer la administraci√≥n general del pa√≠s.**\n",
      "*   **Efectuar los nombramientos de los empleados de la administraci√≥n, excepto los que correspondan al presidente.**\n",
      "*   **Expedir los actos y reglamentos que sean necesarios para ejercer las facultades que le atribuye el art√≠culo y aquellas que le delegue el presidente de la Naci√≥n, con el refrendo del ministro secretario del ramo al cual el acto o reglamento se refiera.**\n",
      "*   **Ejercer las funciones y atribuciones que le delegue el presidente de la Naci√≥n y, en acuerdo de gabinete resolver sobre las materias que le indique el Poder Ejecutivo, o por su propia decisi√≥n, en aquellas que por su importancia estime necesario, en el √°mbito de su competencia.**\n",
      "\n",
      "Adem√°s, es importante destacar que:\n",
      "\n",
      "*   El Presidente no puede ejercer funciones judiciales ni arrogarse el conocimiento de causas pendientes.\n",
      "*   El per√≠odo del Presidente es de cuatro a√±os, sin posibilidad de extensi√≥n.\n"
     ]
    }
   ],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê TEST IT ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "q = \"¬øCu√°les son las atribuciones del presidente de la Argentina?\"\n",
    "print(\"\\nüîé Pregunta:\", q)\n",
    "print(\"\\nüß† Respuesta (Gemini):\\n\", rag_answer(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß™ Procesando f√°ciles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [04:24<00:00,  5.29s/it]\n",
      "üß™ Procesando dif√≠ciles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [06:59<00:00,  6.46s/it]\n",
      "Creating json from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 145.22ba/s]\n",
      "Creating json from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 480.78ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "478500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from ragas.evaluation import evaluate\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def load_reference_answers(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return {item[\"question\"]: item[\"answer\"] for item in data}\n",
    "\n",
    "\n",
    "\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# Construcci√≥n del dataset para RAGAS\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "def prepare_ragas_dataset(reference_answers: dict, tag: str = \"\") -> Dataset:\n",
    "    records = []\n",
    "    for question, reference in tqdm(reference_answers.items(), desc=f\"üß™ Procesando {tag}\"):\n",
    "        retrieved = retrieve(question)\n",
    "        answer = rag_answer(question)\n",
    "        time.sleep(4)\n",
    "        records.append({\n",
    "            \"question\": question,\n",
    "            \"contexts\": retrieved,\n",
    "            \"answer\": answer,\n",
    "            \"reference\": reference\n",
    "        })\n",
    "    return Dataset.from_list(records)\n",
    "\n",
    "\n",
    "reference_easy = load_reference_answers(\"../easy_questions.json\")\n",
    "reference_hard = load_reference_answers(\"../hard_questions.json\")\n",
    "\n",
    "dataset_easy = prepare_ragas_dataset(reference_easy, tag=\"f√°ciles\")\n",
    "dataset_hard = prepare_ragas_dataset(reference_hard, tag=\"dif√≠ciles\")\n",
    "\n",
    "dataset_easy.to_json(\"ragas_easy.json\", orient=\"records\", lines=False)\n",
    "dataset_hard.to_json(\"ragas_hard.json\", orient=\"records\", lines=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrisijjas/Desktop/no itba/juegos/juegos-venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragas.embeddings.base import LangchainEmbeddingsWrapper\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class CustomE5Embedding(LangchainEmbeddingsWrapper):\n",
    "    def __init__(self, model_name=\"dariolopez/bge-m3-es-legal-tmp-6\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_query(self, texts):\n",
    "        texts = [f\"query: {text}\" for text in texts]\n",
    "        return self.model.encode(texts, convert_to_tensor=False)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        texts = [f\"passage: {text}\" for text in texts]\n",
    "        return self.model.encode(texts, convert_to_tensor=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluando preguntas F√ÅCILES:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [25:39<00:00, 10.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados EASY: {'llm_context_precision_with_reference': 0.6391, 'context_recall': 0.7400, 'faithfulness': 0.9058}\n",
      "\n",
      "üìä Evaluando preguntas DIF√çCILES:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 195/195 [47:53<00:00, 14.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados HARD: {'llm_context_precision_with_reference': 0.8095, 'context_recall': 0.8759, 'faithfulness': 0.8608}\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    LLMContextPrecisionWithoutReference,\n",
    "    LLMContextPrecisionWithReference,\n",
    "    NonLLMContextPrecisionWithReference,\n",
    "\n",
    "\n",
    "    ResponseRelevancy,\n",
    "    LLMContextRecall,\n",
    "    Faithfulness\n",
    ")\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas.embeddings.base import embedding_factory\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from ragas.evaluation import evaluate\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "\n",
    "# Load datasets\n",
    "ragas_easy:Dataset = load_dataset(\"json\", data_files=\"ragas_easy.json\", split=\"train\")\n",
    "ragas_hard:Dataset = load_dataset(\"json\", data_files=\"ragas_hard.json\", split=\"train\")\n",
    "\n",
    "# Run config\n",
    "run_config = RunConfig()\n",
    "custom_embeddings = CustomE5Embedding() \n",
    "\n",
    "metrics = [\n",
    "    LLMContextPrecisionWithReference(),\n",
    "    LLMContextRecall(),\n",
    "    Faithfulness()\n",
    "]\n",
    "\n",
    "print(\"\\nüìä Evaluando preguntas F√ÅCILES:\")\n",
    "result_easy = evaluate(\n",
    "    ragas_easy,\n",
    "    metrics=metrics,\n",
    "    run_config=run_config,\n",
    "    batch_size=1\n",
    ")\n",
    "print(\"‚úÖ Resultados EASY:\", result_easy)\n",
    "\n",
    "print(\"\\nüìä Evaluando preguntas DIF√çCILES:\")\n",
    "result_hard = evaluate(\n",
    "    ragas_hard,\n",
    "    metrics=metrics,\n",
    "    run_config=run_config,\n",
    "    batch_size=1\n",
    ")\n",
    "print(\"‚úÖ Resultados HARD:\", result_hard)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e426934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# CSV path\n",
    "csv_path = Path(\"../results.csv\")\n",
    "write_header = not csv_path.exists()\n",
    "\n",
    "metric_names = [\n",
    "    \"llm_context_precision_with_reference\",\n",
    "    \"context_recall\",\n",
    "    \"faithfulness\"\n",
    "]\n",
    "\n",
    "easy_scores = [np.mean(result_easy[m]) for m in metric_names]\n",
    "hard_scores = [np.mean(result_hard[m]) for m in metric_names]\n",
    "\n",
    "with open(csv_path, mode='a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    if write_header:\n",
    "        writer.writerow([\"experiment\", \"dataset\"] + metric_names)\n",
    "\n",
    "    writer.writerow([\"experiment_5\", \"easy\"] + easy_scores)\n",
    "    writer.writerow([\"experiment_5\", \"hard\"] + hard_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juegos-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
